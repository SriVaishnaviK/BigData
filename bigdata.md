# Big Data with examples and types:

Big data in simple terms is vast amount of data which is so complex that none of the traditional data storage or data processing tools can be applied. It is data from various sources which can be structured, unstructured or semi structured data.

Big Data is everywhere; it can be data from networking sites like text, images, audio or video, any organizational data like the healthcare data, educational data, stock market data.

 For instance, if we consider a retailer gathering information on its customers' purchasing patterns, including their past purchases, the time of day they visit, the things they buy, and more, is an example of big data. This information can be utilized to develop customized shopping experiences, comprehend customer preferences, and even forecast upcoming purchasing trends.

## Types of Big Data:

1. Structured Data: As the name suggests it is the data that is organized in a particular format or structure which can be easily stored in relational database. Examples include transactional data, product data, and consumer data.
2. Unstuctured Data: It is the data which does not have a specific format which include text, images, videos, audios.
3. Semi-structured Data: It is partially structured data but not as specific as structured data which include emails, social media posts.

# 6 V’s of Big Data:
1.	Volume: It refers to large amounts of data that is generated from various means which makes it difficult to fit it in a single machine thus requires different tools apart from the traditional ones to process it.
2.	Velocity: Velocity is the speed at which data is being generated. The velocity of data from certain sources in very fast. For instance, millions of people react to a tweet within in no time such data arrives with a very high velocity and is also expected to be processed fast.
3.	Variety: Variety refers to various formats of data. Data can be in the form of tables, images, text, video files, audio files, data from sensors and soon.
4.	Variability: It refers to changes in data over time. Data cannot be consistent always. For example data gathered from a sensor might not be the same always.
5.	Veracity: It refers to the quality of data. There are chances of uncertainty in data. Data is to be cleaned before using it to avoid any unreliability.
6.	Value: It refers to the usefulness of data. The potential insights that can be gained from the data.

# Phases of Big data Analysis:

1.	Acquisition/Recording: Data is collected from various sources such as databases, sensors or social networks and is stored in a storage system such as HDFS or cloud based.
2.	Extraction/Cleaning: Raw data that is collected in cleaned and prepared for analysis. Cleaning the data includes removing missing values, duplicates finding outliers, converting data types,.
3.	Integration/ Aggregation/Representation: The cleaned data is now used for analysis and gain insights by applying statistical methods and performing data analysis. The analyzed data Is also visualized using various visualization tools in different formats like graphs, histograms.
4.	Analysis/Modeling: In this stage, the data is used to make predictions or classify it into groups by applying statistical methods or machine leaning algorithms.
5.	Interpretation: The final phase involves interpreting the results of the analysis and using the insights gained from data. This could comprise sharing the results with relevant parties and applying the learning’s to enhance client engagement, create new products, or streamline business operations.

# Challenges in Big Data Analysis:

1.	Heterogeneity and Incompleteness: No matter how many approaches we use to clean the data, there will always be some uncertainties or inaccuracies. Any variations in the data are incompatible with the model. Prior to analysis, all of the data must be translated to a specific format.
2.	Scale: Another concern with big data analysis is data volume. It is challenging to store, analyze, and interpret the enormous amount of incoming data due to its size and speed of generation. A useful solution might be cloud computing.
3.	Timeliness: Big data analysis aims to uncover relevant information from the data, however when presented with a batch of data, results are anticipated right away. When it comes to big data, the size of the data makes any examination of it time-consuming. As a result, any information that might be extracted from the data likewise takes time.
4.	Privacy: Big data raises privacy concerns since it collects information from a wide variety of sources. The data may include sensitive information, thus it should be handled with prudence.
5.	Human Collaboration: When working across several functional areas, teams, and stakeholders, human collaboration can be a significant challenge in big data analysis. A big data analysis system needs to accommodate input from various human experts as well as collaborative results exploration. We must be ready to handle disagreements, doubt, and mistakes caused by crowd-sourcing platforms like Wikipedia, Yelp reviews.



# References
1.https://www.techtarget.com/searchdatamanagement/definition/big-data

2.https://www.geeksforgeeks.org/5-vs-of-big-data/

3.https://www.javatpoint.com/life-cycle-phases-of-data-analytics

4.https://blog.hubspot.com/website/big-data-challenges